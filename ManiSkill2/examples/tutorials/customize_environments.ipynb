{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/haosulab/ManiSkill2/blob/main/examples/tutorials/customize_environments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2SuqQgZYsswA"
   },
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    # If you run this notebook locally, please change the working directory to the root of the project.\n",
    "    # Otherwise, please use the environment variable `MS2_ASSET_DIR` to specify the asset directory correctly.\n",
    "    %cd ../..\n",
    "    IN_COLAB = False"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvU2cXMBssv9",
    "cellView": "form"
   },
   "source": [
    "# @title Install ManiSkill2 (for Colab)\n",
    "# below fixes some bugs introduced by some recent Colab changes\n",
    "!mkdir -p /usr/share/vulkan/icd.d\n",
    "!wget -q https://raw.githubusercontent.com/haosulab/ManiSkill2/main/docker/nvidia_icd.json\n",
    "!wget -q https://raw.githubusercontent.com/haosulab/ManiSkill2/main/docker/10_nvidia.json\n",
    "!mv nvidia_icd.json /usr/share/vulkan/icd.d\n",
    "!mv 10_nvidia.json /usr/share/glvnd/egl_vendor.d/10_nvidia.json\n",
    "# dependencies\n",
    "!apt-get install -y --no-install-recommends libvulkan-dev\n",
    "!pip install mani_skill2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmObj6IctTtM"
   },
   "source": [
    "Make sure you are using a GPU runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rEIuiAPcwIvh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "45a7daaa-8d2c-49c3-f737-eaf2c10bac20"
   },
   "source": [
    "!nvidia-smi"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVanBf6SsswA"
   },
   "source": [
    "# ManiSkill2 Tutorial: Customize Environments\n",
    "\n",
    "ManiSkill2 comes with improved tooling to customize environments for your own research and applications. In this tutorial, we will showcase how to customize ManiSkill2 environments and will cover the following:\n",
    "- customizing cameras (e.g., resolutions, poses)\n",
    "- adding dynamic objects and static scenes\n",
    "- changing the robot\n",
    "- domain randomization\n",
    "- adjusting lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5tT-BMFqsswB"
   },
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Register ManiSkill2 environments in gym\n",
    "import mani_skill2.envs\n",
    "\n",
    "def plot_img(img, title=None):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.imshow(img)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaSQ7CD2sswC"
   },
   "source": [
    "## Customize Cameras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vTZS3czsswC"
   },
   "source": [
    "The camera configurations are defined during the initialization of an environment and will not change. ManiSkill2 environments all have default camera configurations. You can also update them by passing `camera_cfgs` (cameras for visual observations) and `render_camera_cfgs` (cameras for rendering/visualization only) to the initialization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vybZhIZGsswC",
    "outputId": "3c327106-5e03-44f6-a82c-9e94a7c1db17",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "from mani_skill2.sensors.camera import CameraConfig\n",
    "\n",
    "print(CameraConfig.__init__.__doc__)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75dGgvgKsswD"
   },
   "source": [
    "`camera_cfgs`/`render_camera_cfgs` is a `dict`. The key can be either a property of `CameraConfig` to specify configurations for all cameras, or a camera uid to specify the configuration of a specific camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yVtSCOgIsswD",
    "outputId": "5315bf69-8bd6-4de9-d6de-2cd7b5d16c12",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    }
   },
   "source": [
    "# Change resolutions\n",
    "env = gym.make(\n",
    "    \"PickCube-v0\",\n",
    "    camera_cfgs=dict(base_camera=dict(width=320, height=240)),\n",
    "    render_camera_cfgs=dict(width=640, height=480),\n",
    ")\n",
    "plot_img(env.unwrapped.render_cameras())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VK_9IBdgsswE",
    "outputId": "88c30d72-fa5a-4355-fb64-618758930678",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    }
   },
   "source": [
    "# Change poses and textures\n",
    "from mani_skill2.utils.sapien_utils import look_at\n",
    "\n",
    "pose = look_at([1, -1, 0.5], [0, 0, 0])\n",
    "env = gym.make(\n",
    "    \"PickCube-v0\",\n",
    "    camera_cfgs=dict(texture_names=(\"Color\", \"Position\", \"Segmentation\")),\n",
    "    render_camera_cfgs=dict(p=pose.p, q=pose.q),\n",
    ")\n",
    "plot_img(env.unwrapped.render_cameras())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV1GiuMdsswE"
   },
   "source": [
    "To include segmentation masks for all cameras in observations, you can set `add_segmentation=True` in `camera_cfgs` to initialize an environment, instead of setting texture names for each camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ybNSvICRsswE",
    "outputId": "b1c59a55-cf09-4077-cac7-e06f980a6083",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    }
   },
   "source": [
    "# Add segmentation masks to observations (equivalent to adding Segmentation texture for each camera)\n",
    "env = gym.make(\"PickCube-v0\", camera_cfgs=dict(add_segmentation=True))\n",
    "plot_img(env.unwrapped.render_cameras())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxnk9uHysswF"
   },
   "source": [
    "`camera_cfgs` and `render_camera_cfgs` provide an ad-hoc way to configure cameras. To change default camera configurations, you can inherit the environment class and override `_register_cameras` and `_register_render_cameras`. Note that `_register_cameras` does not handle the cameras associated with the robot.\n",
    "\n",
    "Moreover, to make custom environments you should use the `register_env` function as shown below so you can create them with `gym.make` later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OHpBQW6HsswF",
    "outputId": "a66873f0-7308-4b36-a3f5-89176ad0bcb5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    }
   },
   "source": [
    "from mani_skill2.envs.pick_and_place.pick_cube import PickCubeEnv\n",
    "from mani_skill2.sensors.camera import CameraConfig\n",
    "from mani_skill2.utils.registration import register_env\n",
    "from mani_skill2.utils.sapien_utils import look_at\n",
    "\n",
    "\n",
    "@register_env(\"PickCube-MoreCamera-v0\", max_episode_steps=200, override=True)\n",
    "class PickCubeMoreCameraEnv(PickCubeEnv):\n",
    "    def _register_cameras(self):\n",
    "        pose = look_at([0.3, 0.2, 0.6], [-0.1, 0, 0.1])\n",
    "        left_camera = CameraConfig(\n",
    "            \"left_camera\", pose.p, pose.q, 128, 128, np.pi / 2, 0.01, 10\n",
    "        )\n",
    "\n",
    "        pose = look_at([0.3, -0.2, 0.6], [-0.1, 0, 0.1])\n",
    "        right_camera = CameraConfig(\n",
    "            \"right_camera\", pose.p, pose.q, 128, 128, np.pi / 2, 0.01, 10\n",
    "        )\n",
    "        return [left_camera, right_camera]\n",
    "\n",
    "    def _register_render_cameras(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "env = gym.make(\"PickCube-MoreCamera-v0\")\n",
    "plot_img(env.unwrapped.render_cameras())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQpYLosHsswF"
   },
   "source": [
    "## Add dynamic objects and static scenes\n",
    "\n",
    "In this section, we will showcase how to add dynamic objects and static scenes. As learning generalizable manipulation skills is already challenging, ManiSkill2 does not include widely-studied challenges like visual complexity by default. However, our design enables users to increase visual complexity in a pythonic, straightforward and flexible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AdLdVk1dsswH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aceb5b12-4e58-4bc3-d481-7e4b222b9471"
   },
   "source": [
    "# Download YCB objects\n",
    "if IN_COLAB:\n",
    "  !python -m mani_skill2.utils.download_asset ycb -y\n",
    "else:\n",
    "  !python -m mani_skill2.utils.download_asset ycb\n",
    "# Download an example ReplicaCAD scene from Habitat\n",
    "# You can use other dataset like Gibson or Matterport3D\n",
    "!wget https://dl.fbaipublicfiles.com/habitat/ReplicaCAD/hab2_bench_assets.zip -P data\n",
    "!cd data && unzip -q hab2_bench_assets.zip -d hab2_bench_assets"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uJL0AYMsswH"
   },
   "source": [
    "All the environments in ManiSkill2 follow the same pipeline to reset:\n",
    "\n",
    "```python\n",
    "def reset(self, seed=None, options=dict(reconfigure=False)):\n",
    "    ...\n",
    "    reconfigure = options.get(\"reconfigure\", False)\n",
    "    if reconfigure:\n",
    "        # Reconfigure the scene if assets change\n",
    "        self.reconfigure()\n",
    "    else:\n",
    "        self._clear_sim_state()\n",
    "    ...\n",
    "    self.initialize_episode()\n",
    "```\n",
    "\n",
    "`reconfigure` reconfigures the simulation scene instance. The assets are only loaded during `reconfigure`.\n",
    "\n",
    "```python\n",
    "def reconfigure(self):\n",
    "    \"\"\"Reconfigure the simulation scene instance.\n",
    "    This function should clear the previous scene, and create a new one.\n",
    "    \"\"\"\n",
    "    self._clear()\n",
    "    self._setup_scene()\n",
    "    self._load_agent()  # Load the robot\n",
    "    self._load_actors()  # Load rigid objects\n",
    "    self._load_articulations()  # Load articulated objects\n",
    "    self._setup_cameras()\n",
    "    self._setup_lighting()\n",
    "    ...\n",
    "```\n",
    "\n",
    "`initialize_episode` initializes each episode, and no assets are created.\n",
    "\n",
    "```python\n",
    "def initialize_episode(self):\n",
    "    \"\"\"Initialize the episode, e.g., poses of actors and articulations, and robot configuration.\n",
    "    No new assets are created. Task-relevant information can be initialized here, like goals.\n",
    "    \"\"\"\n",
    "    self._initialize_actors()\n",
    "    self._initialize_articulations()\n",
    "    self._initialize_agent()\n",
    "    self._initialize_task()\n",
    "```\n",
    "\n",
    "However, it is not necessary to strictly follow the order of sub-routines defined in `initialize_episode`.\n",
    "For example, you can initialize the poses in `_initialize_task`, as they can depend on task-relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "id": "arlwfHO2sswH",
    "outputId": "1ca59767-11ff-4d9c-f553-9b8f330a03e7"
   },
   "source": [
    "import sapien.core as sapien\n",
    "\n",
    "from mani_skill2 import ASSET_DIR\n",
    "from mani_skill2.envs.pick_and_place.pick_cube import PickCubeEnv\n",
    "from mani_skill2.sensors.camera import CameraConfig\n",
    "from mani_skill2.utils.registration import register_env\n",
    "from mani_skill2.utils.sapien_utils import look_at\n",
    "\n",
    "\n",
    "@register_env(\"PickYCBInReplicaCAD-v0\", max_episode_steps=200, override=True)\n",
    "class PickYCBInReplicaCAD(PickCubeEnv):\n",
    "    def _load_actors(self):\n",
    "        # Load YCB objects\n",
    "        # It is the same as in PickSingleYCB-v0, just for illustration here\n",
    "        builder = self._scene.create_actor_builder()\n",
    "        model_dir = ASSET_DIR / \"mani_skill2_ycb/models/011_banana\"\n",
    "        scale = self.cube_half_size / 0.01887479572529618\n",
    "        collision_file = str(model_dir / \"collision.obj\")\n",
    "        builder.add_multiple_collisions_from_file(\n",
    "            filename=collision_file, scale=scale, density=1000\n",
    "        )\n",
    "        visual_file = str(model_dir / \"textured.obj\")\n",
    "        builder.add_visual_from_file(filename=visual_file, scale=scale)\n",
    "        self.obj = builder.build(name=\"apple\")\n",
    "\n",
    "        # Add a goal indicator (visual only)\n",
    "        self.goal_site = self._build_sphere_site(self.goal_thresh)\n",
    "\n",
    "        # -------------------------------------------------------------------------- #\n",
    "        # Load static scene\n",
    "        # -------------------------------------------------------------------------- #\n",
    "        builder = self._scene.create_actor_builder()\n",
    "        path = f\"{ASSET_DIR}/hab2_bench_assets/stages/Baked_sc1_staging_00.glb\"\n",
    "        pose = sapien.Pose(q=[0.707, 0.707, 0, 0])  # y-axis up for Habitat scenes\n",
    "        # NOTE: use nonconvex collision for static scene\n",
    "        builder.add_nonconvex_collision_from_file(path, pose)\n",
    "        builder.add_visual_from_file(path, pose)\n",
    "        self.arena = builder.build_static()\n",
    "        # Add offset so that the workspace is on the table\n",
    "        offset = np.array([-2.0616, -3.1837, 0.66467 + 0.095])\n",
    "        self.arena.set_pose(sapien.Pose(-offset))\n",
    "\n",
    "    def initialize_episode(self):\n",
    "        super().initialize_episode()\n",
    "\n",
    "        # Rotate the robot for better visualization\n",
    "        self.agent.robot.set_pose(\n",
    "            sapien.Pose([0, -0.56, 0], [0.707, 0, 0, 0.707])\n",
    "        )\n",
    "\n",
    "    def _register_render_cameras(self):\n",
    "        cam_cfg = super()._register_render_cameras()\n",
    "        cam_cfg.p = cam_cfg.p + [0.5, 0.5, -0.095]\n",
    "        cam_cfg.fov = 1.5\n",
    "        return cam_cfg\n",
    "\n",
    "\n",
    "env = gym.make(\"PickYCBInReplicaCAD-v0\")\n",
    "plot_img(env.unwrapped.render_rgb_array())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLUv2jt6sswI"
   },
   "source": [
    "## Change the Robot\n",
    "\n",
    "In this section, we will showcase how to customize the existing robot and add a new robot. In ManiSkill2, the agent is a collection of the robot, mounted cameras, and controllers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhhJgxqvsswI"
   },
   "source": [
    "### Customize the existing robot\n",
    "\n",
    "We provide an agent implementation of Franka Emika, `Panda`, and different agent configurations in `mani_skill2.agents.configs.panda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TKj8AhLCsswI",
    "outputId": "90517a63-aa23-417c-f8d0-140fd81da1c2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "from mani_skill2.agents.base_agent import AgentConfig\n",
    "\n",
    "# The agent config should follow the signature, but is not required to inherit from AgentConfig\n",
    "print(AgentConfig.__doc__)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hWCTIy3sswI"
   },
   "source": [
    "The next cell shows some ways to customize the robot, including changing materials, URDF, and controller. Importantly the robot configuration is also where you can customize mounted cameras.\n",
    "\n",
    "More advanced examples can be found in `mani_skill2.agents.configs.panda.variants`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kCcS_sd9sswI",
    "outputId": "833377fe-c26c-4032-fdbc-6c2a58373960",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    }
   },
   "source": [
    "from copy import deepcopy\n",
    "from mani_skill2.envs.pick_and_place.pick_cube import PickCubeEnv\n",
    "from mani_skill2.utils.registration import register_env\n",
    "from mani_skill2.utils.sapien_utils import get_entity_by_name\n",
    "\n",
    "from mani_skill2.agents.base_agent import BaseAgent  # base class of other agents\n",
    "from mani_skill2.agents.robots.panda import Panda\n",
    "from mani_skill2.agents.configs.panda.defaults import PandaDefaultConfig\n",
    "from mani_skill2.agents.controllers.pd_joint_pos import PDJointPosControllerConfig\n",
    "\n",
    "\n",
    "class PandaCustomConfig(PandaDefaultConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Example: You can change the path to your customized URDF file\n",
    "        # panda_v3 add a camera collision mounted on the hand\n",
    "        self.urdf_path = \"{PACKAGE_ASSET_DIR}/descriptions/panda_v3.urdf\"\n",
    "\n",
    "        # Example: change physical parameters (e.g., friction)\n",
    "        # urdf_config will be parsed by `mani_skill2.utils.sapien_utils.parse_urdf_config`\n",
    "        self.urdf_config[\"_materials\"] = dict(\n",
    "            gripper=dict(static_friction=5.0, dynamic_friction=5.0, restitution=0.0)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def controllers(self):\n",
    "        controllers = super().controllers\n",
    "\n",
    "        # Example: Change parameters of the existing controller\n",
    "        arm_controller: PDJointPosControllerConfig = controllers[\"pd_joint_pos\"][\"arm\"]\n",
    "        arm_controller.stiffness = 500  # kp in PD controller\n",
    "\n",
    "        # Example: Add a new controller\n",
    "        new_arm_controller = deepcopy(arm_controller)\n",
    "        new_gripper_controller = PDJointPosControllerConfig(\n",
    "            self.gripper_joint_names,\n",
    "            lower=0,\n",
    "            upper=0.04,\n",
    "            stiffness=500,\n",
    "            damping=50,\n",
    "            force_limit=100,\n",
    "        )\n",
    "        controllers[\"pd_joint_pos_new\"] = dict(\n",
    "            arm=new_arm_controller, gripper=new_gripper_controller\n",
    "        )\n",
    "\n",
    "        return controllers\n",
    "\n",
    "    @property\n",
    "    def cameras(self):\n",
    "        # Example: Override the camera configuration (e.g., resolution and mounted actor)\n",
    "        return CameraConfig(\n",
    "            uid=\"hand_camera\",\n",
    "            p=[0, 0, 0],\n",
    "            q=[1, 0, 0, 0],\n",
    "            width=256,\n",
    "            height=256,\n",
    "            fov=1.57,\n",
    "            near=0.01,\n",
    "            far=10,\n",
    "            actor_uid=\"camera_link\",\n",
    "        )\n",
    "\n",
    "\n",
    "@register_env(\"PickCube-CustomPanda-v0\", max_episode_steps=200, override=True)\n",
    "class PickCubeCustomPandaEnv(PickCubeEnv):\n",
    "    def _configure_agent(self):\n",
    "        # This function will be called in __init__ so that the configurations of mounted cameras can be decided.\n",
    "        self._agent_cfg = PandaCustomConfig()\n",
    "        # You can also modify the agent configuration here in an ad-hoc way\n",
    "\n",
    "    def _load_agent(self):\n",
    "        self.agent = Panda(\n",
    "            self._scene, self._control_freq, self._control_mode, config=self._agent_cfg\n",
    "        )\n",
    "        self.tcp: sapien.Link = get_entity_by_name(\n",
    "            self.agent.robot.get_links(), self.agent.config.ee_link_name\n",
    "        )\n",
    "\n",
    "\n",
    "env = gym.make(\"PickCube-CustomPanda-v0\", control_mode=\"pd_joint_pos_new\")\n",
    "print(\"control_mode\", env.control_mode)\n",
    "plot_img(env.unwrapped.render_cameras())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COJF1BOVsswJ"
   },
   "source": [
    "### Add a new robot\n",
    "\n",
    "Adding a new robot in ManiSkill2 includes several aspects:\n",
    "- Download or create URDF and assets (usually from the ROS package).  \n",
    "- Implement an agent class inherited from `BaseAgent`\n",
    "- Implement agent configurations (controllers, cameras, ...)\n",
    "- Support the new agent class in the environment\n",
    "\n",
    "We refer readers to our implementation of Xmate3 as an example. The environments in `mani_skill2.envs.pick_and_place` all support Xmate3.\n",
    "\n",
    "```python\n",
    "from mani_skill2.agents.robots.xmate3 import Xmate3Robotiq\n",
    "from mani_skill2.agents.configs.xmate3.defaults import Xmate3RobotiqDefaultConfig\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "H9JpSvh8sswJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a3c536fe-c661-4b90-bf1b-ebd3a7969cfb"
   },
   "source": [
    "# Download the assets of Xmate3 and robotiq\n",
    "!python -m mani_skill2.utils.download_asset xmate3_robotiq"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2JUfzjzYsswJ",
    "outputId": "c0e28cf3-ba32-46af-8851-19efb7cdc615",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    }
   },
   "source": [
    "env = gym.make(\"PickCube-v0\", robot=\"xmate3_robotiq\")\n",
    "plot_img(env.unwrapped.render_cameras())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfCa9yZ5sswJ"
   },
   "source": [
    "## Domain randomization\n",
    "\n",
    "In this section, we will showcase how to add domain randomization (e.g., visual appearance, physical parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nGwgsxvsswK"
   },
   "source": [
    "First, we show how we randomize physical parameters and visual apperance, which can be applied without reconfiguring the simulation scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6pFadnAesswK",
    "outputId": "cd732004-6f5b-43c4-cd4a-b1c13692342f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "import sapien.core as sapien\n",
    "\n",
    "from mani_skill2.envs.pick_and_place.pick_cube import PickCubeEnv\n",
    "from mani_skill2.utils.registration import register_env\n",
    "from mani_skill2.utils.sapien_utils import set_render_material\n",
    "\n",
    "\n",
    "@register_env(\"DR-PickCube-v0\", max_episode_steps=100, override=True)\n",
    "class DomainRandomizationPickCubeEnv(PickCubeEnv):\n",
    "    def _initialize_actors(self):\n",
    "        super()._initialize_actors()\n",
    "\n",
    "        # Example: randomize friction\n",
    "        friction = self._episode_rng.uniform(0.5, 1.0)\n",
    "        phys_mtl = self._scene.create_physical_material(\n",
    "            static_friction=friction, dynamic_friction=friction, restitution=0.1\n",
    "        )\n",
    "        for cs in self.obj.get_collision_shapes():\n",
    "            cs.set_physical_material(phys_mtl)\n",
    "\n",
    "        # Example: randomize damping\n",
    "        linear_damping = self._episode_rng.uniform(0, 1.0)\n",
    "        angular_damping = self._episode_rng.uniform(0, 1.0)\n",
    "        self.obj.set_damping(linear_damping, angular_damping)\n",
    "\n",
    "        # Example: randomize color\n",
    "        color = self._episode_rng.uniform(0.5, 1.0, size=3)\n",
    "        for vb in self.obj.get_visual_bodies():\n",
    "            for rs in vb.get_render_shapes():\n",
    "                set_render_material(rs.material, color=np.hstack([color, 1.0]))\n",
    "\n",
    "\n",
    "env = gym.make(\"DR-PickCube-v0\")\n",
    "for _ in range(3):\n",
    "    env.reset()\n",
    "    plot_img(env.unwrapped.render_rgb_array())\n",
    "env.close()\n",
    "del env\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7K-3ZcF7sswK"
   },
   "source": [
    "Next, we show how to randomize object properties, which require reconfiguring the simulation scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aWl18WF1sswK",
    "outputId": "1aeca65e-055c-4950-9b80-36ff87f7d9e9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "import sapien.core as sapien\n",
    "\n",
    "from mani_skill2.envs.pick_and_place.pick_cube import PickCubeEnv\n",
    "from mani_skill2.utils.registration import register_env\n",
    "\n",
    "\n",
    "@register_env(\"DR-PickCube-v1\", max_episode_steps=100, override=True)\n",
    "class DomainRandomizationPickCubeEnvV1(PickCubeEnv):\n",
    "    # Reconfigure the environment when reset by default\n",
    "    def reset(self, seed=None, options=None):\n",
    "        return super().reset(seed, options=dict(reconfigure=True))\n",
    "\n",
    "    def _load_actors(self):\n",
    "        self.cube_half_size = self._episode_rng.uniform(0.01, 0.03, size=3)\n",
    "        super()._load_actors()\n",
    "\n",
    "\n",
    "env = gym.make(\"DR-PickCube-v1\")\n",
    "for _ in range(3):\n",
    "    env.reset()\n",
    "    plot_img(env.unwrapped.render_rgb_array())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSM8R5GxsswK"
   },
   "source": [
    "## Adjust lighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6N1ficpOsswK"
   },
   "source": [
    "You can enable shadows to improve photorealism as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "VxOZld2msswK",
    "outputId": "0c055eb8-d73e-463d-806f-9cbd6c4588fc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    }
   },
   "source": [
    "env = gym.make(\"PickCube-v0\", enable_shadow=True)\n",
    "plot_img(env.unwrapped.render_cameras())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFarHZ7XsswM"
   },
   "source": [
    "You can override `_setup_lighting` to modify lighting directly as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aKFcNf_JsswM",
    "outputId": "36bb4ff0-e024-4495-b33b-ff293ba24eec",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    }
   },
   "source": [
    "from mani_skill2.envs.pick_and_place.pick_cube import PickCubeEnv\n",
    "from mani_skill2.utils.registration import register_env\n",
    "\n",
    "\n",
    "@register_env(\"PickCube-Light-v0\", max_episode_steps=100, override=True)\n",
    "class PickCubeLightEnv(PickCubeEnv):\n",
    "    def _setup_lighting(self):\n",
    "        shadow = self.enable_shadow\n",
    "        self._scene.set_ambient_light([0.3, 0.3, 0.3])\n",
    "        # Only the first of directional lights can have shadow\n",
    "        self._scene.add_directional_light(\n",
    "            [1, 1, -1], [1, 1, 1], shadow=shadow, scale=5, shadow_map_size=2048\n",
    "        )\n",
    "        self._scene.add_directional_light([-1, -1, -1], [1, 1, 1])\n",
    "        self._scene.add_point_light([1, 0, 1], [1, 0, 0], shadow=shadow)\n",
    "        self._scene.add_point_light([-0.5, 1, 1], [0, 1, 0], shadow=shadow)\n",
    "        self._scene.add_point_light([-0.5, -1, 1], [0, 0, 1], shadow=shadow)\n",
    "\n",
    "\n",
    "env = gym.make(\"PickCube-Light-v0\")\n",
    "plot_img(env.unwrapped.render_rgb_array())\n",
    "env.close()\n",
    "del env"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "mani_skill2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce90f07845ba38ab59fee1876930aa47237715b066c51d465442b5065c556344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
